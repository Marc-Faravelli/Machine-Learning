---
title: "CASO PRACTICO TAXI FLOTA AYTO. MADRID"
author: "Marc Faravelli Rodriguez"
date: "14/12/2020"
output: html_document
---
```{r}
rm(list = ls()) # Limpiar la memoria
```
# INSTALAR LIBRERÍAS
-------------------------------------------------------------------
```{r}
library(ggplot2)
library(tidyverse)
library(dplyr)
library(caTools)
library(ROCR)
library(randomForest)
library(rpart)
library(rpart.plot)
library(e1071)
library(factoextra)
library(class)
library(cluster)
library(gridExtra)
library(grid) 
library(cowplot)
library(magrittr)
library(Rcpp)
library(RcppEigen)
library(rstan)
```
# CARGAR DATOS
-------------------------------------------------------------------
Los datos se cargaron a partir del siguiente comando:

# Datos de la Flota de Taxis de la ciudad de Madrid.

```{r}
taxiFlota<-read.csv("http://www.diegocalvo.es/wp-content/uploads/2019/11/taxiFlota.csv",sep = ";",header=TRUE)

#Visualización de los datos
head(taxiFlota, 5)
```

Observando la tabla, podemos ver que los datos se refieren a Taxis y están desglosados en matrículas, fecha de matriculación, marca, modelo y otros datos que se utilizarán en el modelo. Por otro lado, se constata que las 3 ultimas columnas no aportan valor a los analisis y por este motivo se eliminarán utilizando el siguiente comando:

#EXPLORAR LA INFORMACIÓN
```{r}
#Para los modelos, solo se utilizarán las columnas de: "Fecha.Matriculación","Combustible","Clasificación.medioambiental"
taxiFlota <- taxiFlota[, c("Fecha.Matriculación", "Combustible", "Clasificación.medioambiental")]

taxiFlota <- na.omit(taxiFlota) #Eliminación de los valores nulos
head(taxiFlota,5)
```
```{r}
#Asignación de valores a las columnas

taxiFlota <-  taxiFlota %>%  mutate(Fecha.Matriculación = strtoi(stringi::stri_sub(Fecha.Matriculación, from = -4,,4)),)
taxiFlota$Clasificación.medioambiental <- as.factor(taxiFlota$Clasificación.medioambiental)
taxiFlota$Combustible <- as.factor(taxiFlota$Combustible)
```
```{r}
#Exploración de los datos

summary(taxiFlota)
```

Exploraramos los datos con un gráfico de barras:
```{r}
plot(taxiFlota$Combustible)
```
Observando el gráfico, se puede ver como el combustible más usado es el Diesel, seguido de la Gasolina.

#PREPARACIÓN DE LOS DATOS
```{r}
#Se fija una semilla para que los datos aleatorios siempre salgan iguales
set.seed(1234)

#Se utiliza la variable "Clasificación ambiental", ya que es la variable que se quiere predecir con los datos del modelo.

#Se divide los datos en dos:
split <- sample.split(taxiFlota$Clasificación.medioambiental, SplitRatio = 0.75)

#1) Entrenamiento
training <- subset(taxiFlota, split == TRUE)

#2) Test
test <- subset(taxiFlota, split == FALSE)

#Revisión de los datos
summary(training)
```
```{r}
#Exploración de los datos de test
nrow(training)
```
```{r}
nrow(test)
```
Se puede observar que hay 35188 datos en el entrenamiento y 11730 en el test.

#MODELO SVM (Support Vector Machine)
```{r}
#Permite usar de forma directa la variable
attach(training)

#DEFINIR EL MODELO Y VISUALIZAR
model1 <- svm(training$Clasificación.medioambiental ~ ., #Se indica la variable predictora
                
data=training, # El conjunto de datos a utilizar

type = 'C-classification', #Indica el tipo de clasificador

kernel = 'radial') #Indica el nucleo utilizado en el entrenamiento

#Resumen del modelo
summary(model1)
```
Se puede observar que los parametros del modelo estan compuestos por 1545 vectores y 4 clases.

#PREDICCIÓN DEL MODELO SVM
```{r}
prediction1 <- predict(model1, newdata = test)
prediction1
```
#EVALUACIÓN DEL MODELO - ANALISIS DE RESIDUOS
```{r}
# 1) Matriz de confusión
#Definición de la matriz de confusión
confusionMatrix1 <- table (test$Clasificación.medioambiental, prediction1)
confusionMatrix1
```
```{r}
#Analisis del porcentaje de aciertos, dividir la diagonal entre el total de aciertos
(correctos <- sum(diag(confusionMatrix1))/nrow(test)*100)
```
Podemos observar que el modelo acierta un 98,32 %. Los mayores errores se producen al procesar la predicción de "Clasificación ambientalECO".

#ARBOL DE DECISIÓN
```{r}
#DEFINIR EL MODELO Y VISUALIZAR
model2 <- rpart(training$Clasificación.medioambiental ~ ., # se indican las variables predictoras
data=training )
#resumen del modelo
summary(model2)
```
A continuación podemos ver el detalle del modelo de Arbol de decisión:
```{r}
#Visualización del arbol de decisión
rpart.plot(model2)
```

Podemos ver que el combustible Diesel, Electrico y Gasolina estan clasificados como B, mientras que la clasificacion ambiental ECO esta explicado principalmente por Gasolina Transformado GLP.

```{r}
#PREDICCION DEL MODELO ARBOL DE DECISIÓN
prediction2 <- predict(model2, newdata = test, type="class")
prediction2
```
```{r}
#EVALUACIÓN DEL MODELO - ANALISIS DE RESIDUOS PARA ARBOL DE DECISIÓN
# 1) Matriz de confusión
#Definicón de la matriz de confusión
confusionMatrix2 <- table (test$Clasificación.medioambiental, prediction2)
confusionMatrix2
```
```{r}
#Analisis del porcentaje de aciertos, dividir la diagonal entre el total de aciertos
(correctos2 <- sum(diag(confusionMatrix2))/nrow(test)*100)
```
Este modelo define el 97,93% de la variable.

#MODELO BOSQUES ALEATORIOS (RAMDOM FOREST)
```{r}
#DEFINIR EL MODELO Y VISUALIZAR
model3 <- randomForest(training$Clasificación.medioambiental ~ ., #Se indica la variable predictora
data=training, #Se indica el conjunto de datos a usar
ntree=50) #Número de arboles
model3
```

Al revisar el modelo podemo observar que tiene un error de un 1,67%

```{r}
#PREDICCIÓN DEL MODELO
prediction3 <- predict(model3, newdata =test)
prediction3
```
```{r}
#EVALUACIÓN DEL MODELO - ANALISIS DE RESIDUOS PARA RANDOM FOREST
# 1) Matriz de confusión
#Definición de la matriz de confusión
confusionMatrix3 <- table (test$Clasificación.medioambiental, prediction3)
confusionMatrix3
```
```{r}
# Analisis del porcentaje de aciertos, dividir diagonal entre el total de aciertos
(correctos3 <- sum(diag(confusionMatrix3))/nrow(test)*100)
```
Este modelo explica el 98,32% de los datos.

#MODELO CUANTIFICADOR BAYESIANO INGENUO
```{r}
#DEFINIR EL MODELO Y VISUALIZAR
model4 <- naiveBayes(training$Clasificación.medioambiental ~ ., #Se indica la variable predictora
data=training, #Se indica el conjunto de datos a usar
laplace=0) #Número de arboles
model4
```
```{r}
#PREDICCIÓN DEL MODELO
prediction4 <- predict(model4, newdata =test)
prediction4
```
```{r}
#EVALUACIÓN DEL MODELO - ANALISIS DE RESIDUOS PARA CUANTIFICADOR BAYESIANO INGENUO
# 1) Matriz de confusión
#Definiciónde la matriz de confusión
confusionMatrix4 <- table (test$Clasificación.medioambiental, prediction4)
confusionMatrix4
```
```{r}
#Analisis del porcentaje de aciertos, dividir la diagonal entre el total de aciertos
(correctos4 <- sum(diag(confusionMatrix4))/nrow(test)*100)
```
Este modelo tiene un 98,03% de predicción

#RESUMEN DE LOS ANALISIS 
```{r}
#Analisis del porcentaje de predicción de Support Vector Machine
(correctos1 <- sum(diag(confusionMatrix1))/nrow(test)*100)
```
```{r}
#Analisis del porcentaje de predicción de Arbol de desición
(correctos2 <- sum(diag(confusionMatrix2))/nrow(test)*100)
```
```{r}
#Analisis del porcentaje de predicción de Ramdon Forest
(correctos3 <- sum(diag(confusionMatrix3))/nrow(test)*100)
```
```{r}
#Analisis del porcentaje de predicción de Cuantificador Bayesiano Ingenuo
(correctos4 <- sum(diag(confusionMatrix4))/nrow(test)*100)
```
Después de haber hecho los analisis de predicción podemos destacar 2 algoritmos ya que tienen un porcentaje mayor respecto a los otros dos: Support Vector Machine y Ramdom Forest (98,32%).

En tercer lugar tenemos al Cuantificador Bayesiano con un 98,03% y por ultimo el Arbol de decisión con un 97,93%.
